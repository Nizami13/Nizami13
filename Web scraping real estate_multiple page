# -*- coding: utf-8 -*-
"""Web scrapping multiple pages_real estate.ipynb

Automatically generated by Colaboratory.



from bs4 import BeautifulSoup
import requests
import pandas as pd

#Puting all together
#creating empty dataframe
real_estate = pd.DataFrame(columns=['Street','Beds', 'Baths', 'Price'])

#scrap 10 pages
#sequence of numbers 1 up to 10 , bcs 11 is excluded
for i in range(1,11):
  #bcs only page number change and we make it string element
  website= requests.get('https://www.trulia.com/NY/New_York/' + str(i) + '_p/')
  #create soup object
  soup = BeautifulSoup(website.content, 'html.parser')
  #result items
  result = soup.find_all('li', {'class':'SearchResultsList__WideCell-b7y9ki-2'})
  #update results
  results_update=[]
  for r in result:
    if r.has_attr('data-testid'):
      results_update.append(r)
  #lists
  streets = [result.find('div', {'data-testid':'property-address'}).get_text() for result in results_update] 
  beds = []
  for result in results_update:
    try:
        beds.append(result.find('div', {'data-testid':'property-beds'}).get_text())
    except:
        beds.append('n/a')
  baths = []
  for result in results_update:
    try:
        baths.append(result.find('div', {'data-testid':'property-baths'}).get_text())
    except:
        baths.append('n/a')
  price = [result.find('div', {'data-testid':'property-price'}).get_text() for result in results_update]

  
  for k in range(len('streets')):
    real_estate = real_estate.append({'Street': streets[k], 'Beds': beds[k], 'Baths': baths[k], 'Price': price[k]}, ignore_index=True)

real_estate

#info about dataframe
real_estate.info()

#although you did 10 pages and in each page there are 40 lists,  but in each page there was not enough information for all variables
#so, only 70 were available.

#print first 5 results
real_estate.head()

real_estate.tail()

#Data cleaning
#remove bd and ba
real_estate['Beds']=real_estate['Beds'].apply(lambda x: x.strip('bd'))
real_estate['Baths']=real_estate['Baths'].apply(lambda x: x.strip('ba'))

#So Updated Data Frame after removing bd and ba will be
real_estate

real_estate.to_excel('real_estate_multiple_pages.xlsx', index=False)
