# -*- coding: utf-8 -*-
"""Results_restaurants_multiple page_advanced.ipynb

Automatically generated by Colaboratory.



from bs4 import BeautifulSoup
import requests
import pandas as pd 
import urllib.parse

#Put all together
#create dataframe, in the begining it is empty
df_restaurant=pd.DataFrame(columns=['Restaurant Name', 'Address', 'Email', 'Homepage', 'Info'])
#sequence of numbers from 1 to 3, 4 is not included
for i in range(1,4):
  website = 'https://www.yellowpages.com/search?search_terms=restaurant&geo_location_terms=New%20York%2C%20NY&page=' +str(i)
  response = requests.get(website)

  #create soup object
  soup=BeautifulSoup(response.content, 'html.parser')

  #result container
  result_container = soup.find_all('div', {'class':'result'})

  #url part 1
  url_part_1 = 'https://www.yellowpages.com/'

  url_part_2=[]

  #url part 2
  for item in result_container:
    # loop through links
    for link in item.find_all('a', {'class': 'business-name'}):
        url_part_2.append(link.get('href'))

  #join url1 to url2 in order to get absolute url
  url_joined = []
  
  for link_2 in url_part_2:
    url_joined.append(urllib.parse.urljoin(url_part_1, link_2))

  # loop through all joined links
  for link in url_joined:
    response = requests.get(link)
    
    # create soup object
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # name
    try:
        name = soup.find('h1').get_text()
    except:
        name = 'n/a'
        
    # address 
    try:
        address = soup.find('h2', {'class': 'address'}).get_text()
    except:
        address = 'n/a'
        
    # phone
    try:
        phone = soup.find('p', {'class':'phone'}).get_text()
    except:
        phone = 'n/a'
        
    # email
    try:
        email = soup.find('a', {'class': 'email-business'}).get('href').split('mailto:')[1]
    except:
        email = 'n/a'
        
    # website
    try:
        website = soup.find('a', {'class': 'website-link'}).get('href')
    except:
        website = 'n/a'
        
    # general info
    try:
        info = soup.find('dd', {'class': 'general-info'}).get_text()
    except:
        info = 'n/a'

    #Pandas dataframe
    df_restaurant=df_restaurant.append({'Restaurant Name':name,'Address':address,'Email':email, 'Homepage':website, 'Info':info}, ignore_index=True)

#Output
df_restaurant

#store in Excel
df_restaurant.to_excel('results_multiplte_pages_YellowPage.xlsx', index=False)
