# -*- coding: utf-8 -*-
"""web scrapping houses prices.ipynb

Automatically generated by Colaboratory.



from bs4 import BeautifulSoup
import requests
import pandas as pd

website='https://www.trulia.com/CA/San_Francisco/'

response=requests.get(website)

response.status_code

soup=BeautifulSoup(response.content,'html.parser')

soup

#taking ul unordered value and looking at list search results class
result = soup.find_all('li', {'class':'SearchResultsList__WideCell-b7y9ki-2'})

len(result)

# so in our website we have 40 but it shows 42 resultss
#some result elemets makes no sense for us. wehave to analyze what is the difference between different list
#some data does not have attribute (data-testid) so we have to ignore it
#so lets update result list
results_update=[]

for r in result:
  if r.has_attr('data-testid'):
    results_update.append(r)

len(results_update)

#so you can see that we ignored data without attributes
#and we have 40 data

#we need below data
#street
#bedrrom
#bathroom
#price

#first we do street

results_update[1].find('div', {'data-testid':'property-address'}).get_text()

#bedroom

results_update[0].find('div', {'data-testid':'property-beds'}).get_text()

#bathroom
results_update[7].find('div', {'data-testid':'property-baths'}).get_text()

results_update[0].find('div', {'data-testid':'property-price'}).get_text()

#Put all results in 1 list, bath did not work with normal, bcs some bathroom not available, so used other code

streets = [result.find('div', {'data-testid':'property-address'}).get_text() for result in results_update] 
beds = [result.find('div', {'data-testid':'property-beds'}).get_text() for result in results_update] 
price = [result.find('div', {'data-testid':'property-price'}).get_text() for result in results_update]

baths = []
for result in results_update:
    try:
        baths.append(result.find('div', {'data-testid':'property-baths'}).get_text())
    except:
        baths.append('n/a')

real_estate = pd.DataFrame({'Street':streets, 'Bedroom':beds, 'Bathroom':baths, 'Price':price})

real_estate.to_excel('real_estate_page_1.xlsx',index=False)

#so we scrapped only the first page and saved the file, now we scrap all pages

